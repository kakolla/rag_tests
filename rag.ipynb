{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U --quiet \\\n",
    "    \"pinecone\" \\\n",
    "    \"langchain-pinecone\" \\\n",
    "    \"langchain-openai\" \\\n",
    "    \"langchain-ollama\" \\\n",
    "    \"langchain-community\" \\\n",
    "    \"langchain-core\" \\\n",
    "    \"langchain\" \\\n",
    "    \"langchain-text-splitters\" \\\n",
    "    \"dotenv\" \\\n",
    "    \"pypdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48891e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekkakolla/code/curve/rag/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/abhishekkakolla/code/curve/rag/.venv/lib/python3.11/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone.vectorstores import PineconeVectorStore \n",
    "\n",
    "# chunking functions\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# llm and embeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import ChatOllama  \n",
    "\n",
    "# langchain rag\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087021f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API keys loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# api keys\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not PINECONE_API_KEY or not OPENAI_API_KEY:\n",
    "    print(\"Error: API keys not found. Please create a .env file.\")\n",
    "else:\n",
    "    print(\"API keys loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40a8643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'vanilla-rag-ollama' already exists.\n"
     ]
    }
   ],
   "source": [
    "# connect to pinecone\n",
    "INDEX_NAME = \"vanilla-rag-ollama\"\n",
    "EMBEDDING_DIMENSION = 1536 # Dimension for OpenAI's text-embedding-3-small\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Create the index if it doesn't exist\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    print(f\"Creating index '{INDEX_NAME}'...\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=EMBEDDING_DIMENSION,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(\"Index created.\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2cc2de",
   "metadata": {},
   "source": [
    "### Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingestion\n",
    "print(\"Loading documents from '12_papers'...\")\n",
    "loader = DirectoryLoader(\n",
    "    '12_papers',                  # The folder to load from\n",
    "    glob=\"**/*.pdf\",              # Pattern to match only PDF files\n",
    "    loader_cls=PyPDFLoader,       # Use PyPDFLoader to read the files\n",
    "    show_progress=True\n",
    ")\n",
    "raw_docs = loader.load()\n",
    "\n",
    "if not raw_docs:\n",
    "    print(\"Error: No PDF files found in '12_papers'. Make sure they are in the correct directory.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(raw_docs)} documents.\")\n",
    "\n",
    "# split into chunk\n",
    "print(\"Splitting documents into chunks...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  \n",
    "    chunk_overlap=200\n",
    ")\n",
    "all_splits = text_splitter.split_documents(raw_docs)\n",
    "print(f\"Split into {len(all_splits)} chunks.\")\n",
    "\n",
    "# embed models\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "print(\"Embedding and ingesting chunks..\")\n",
    "docsearch = PineconeVectorStore.from_documents(  \n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    index_name=INDEX_NAME\n",
    ")\n",
    "print(\"Ingestion complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101a5bc",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9b544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "docsearch = PineconeVectorStore(\n",
    "    index_name=INDEX_NAME,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c1fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOllama(\n",
    "    model=os.getenv(\"FLASH_LLM\"), # Use env var, but default to gemma2:9b\n",
    "    base_url=os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\"),\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# Pull the standard RAG prompti\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "\n",
    "# create chain\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm, retrieval_qa_chat_prompt\n",
    ")\n",
    "\n",
    "# retriever\n",
    "retriever = docsearch.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf0bc2",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7004e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What do astrocytes contribute to Alzheimer's?\n",
      "\n",
      "Answer:\n",
      "Astrocytes contribute to Alzheimer's disease by displaying fragmented\n",
      "morphology, which can lead to neurotoxicity. Additionally, they are\n",
      "involved in the clearance of plaque buildup and other cellular debris.\n",
      "Reactive A1 astrocytes induced by microglial cytokines become toxic\n",
      "and directly contribute to neuronal death in neurodegenerative\n",
      "diseases, highlighting astrocyte regulation as a therapeutic target in\n",
      "Alzheimer's disease.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "question = \"What do astrocytes contribute to Alzheimer's?\" \n",
    "print(f\"\\nQuery: {question}\")\n",
    "\n",
    "# Invoke the chain\n",
    "response = retrieval_chain.invoke({\"input\": question})\n",
    "print(\"\\nAnswer:\")\n",
    "ans = response[\"answer\"]\n",
    "wrapped_text = textwrap.fill(ans, width=70)\n",
    "print(wrapped_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
